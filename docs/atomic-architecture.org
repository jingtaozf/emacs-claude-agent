# -*- mode: org; -*-
#+TITLE: Atomic Architecture Analysis for claude-agent
#+SUBTITLE: Automated Procedures and Memory for AI Coding Agents
#+AUTHOR: Claude Agent SDK
#+DATE: 2024
#+OPTIONS: toc:3

* Introduction

This document analyzes the [[https://github.com/flora131/agent-instructions][Atomic]] framework (flora131/agent-instructions)
and how its patterns can benefit claude-org-mode. Atomic is a comprehensive infrastructure
for autonomous AI coding agents that shipped *100,000+ lines of production code in two weeks*.

The name "Atomic" reflects its approach of decomposing complex goals into *discrete,
manageable steps* following core Software Development Lifecycle (SDLC) principles.

* Core Philosophy

** The Memory Gap

AI coding agents have three types of memory:

| Memory Type  | Description      | Out of Box             | Atomic Solution      |
|--------------+------------------+------------------------+----------------------|
| *Semantic*   | Facts about code | "Auth is in /src/auth" | Via coding agent     |
| *Episodic*   | What happened    | Fragmented             | specs, progress.txt  |
| *Procedural* | How to do things | Missing                | Automated procedures |

Atomic fills the *episodic* and *procedural* gaps through structured specifications
and standardized workflows.

** The Flywheel

#+begin_example
Research → Specs → Execution → Outcomes → Specs (persistent memory)
              ↑                                    ↓
              └────────────────────────────────────┘
#+end_example

Every feature follows proven SDLC best practices. Specs aren't just documentation—
they're *persistent memory* that survives sessions and informs future agents.

** The 40-60 Rule

Agents get you 40-60% of the way there. Humans provide the remaining polish through:
- Reviewing specs before implementation (architecture decisions)
- Reviewing code after each feature (quality gate)
- Using =/compact= to manage context between steps

*You own the decisions. Agents own the execution.*

* Architecture Components

** Three Resource Types

| Resource | Purpose | Examples |
|----------+---------+----------|
| *Commands* | Orchestrate agents | =/research-codebase=, =/create-spec=, =/implement-feature= |
| *Agents* | Execute specialized tasks | =codebase-analyzer=, =codebase-locator=, =pattern-finder= |
| *Skills* | Inject domain knowledge | =testing-anti-patterns=, =prompt-engineer= |

*Commands* call *Agents* to do the work, while *Skills* ensure they follow best practices.

** The Nine Commands

| Command | Model | Purpose |
|---------+-------+---------|
| =/research-codebase= | opus | Deep codebase analysis with parallel sub-agents |
| =/create-spec= | opus | Generate RFC/design doc from research |
| =/create-feature-list= | sonnet | Break spec into =feature-list.json= |
| =/implement-feature= | sonnet | Implement ONE feature from list |
| =/create-debug-report= | opus | Debugging assistant with root cause analysis |
| =/compact= | sonnet | Session summarization for handoff |
| =/commit= | sonnet | Git commit workflow |
| =/create-pr= | sonnet | Pull request creation |
| =/explain-code= | sonnet | Code explanation |

** The Six Agents

All agents are *documentarians, not critics*—they describe what exists without
suggesting improvements or identifying issues.

| Agent | Purpose | Tools |
|-------+---------+-------|
| =codebase-locator= | Find WHERE files live | Glob, Grep, LS |
| =codebase-analyzer= | Understand HOW code works | Glob, Grep, Read |
| =codebase-pattern-finder= | Find existing patterns with code examples | Glob, Grep, Read |
| =codebase-research-locator= | Discover what research documents exist | Glob, Grep, Read |
| =codebase-research-analyzer= | Extract insights from research docs | Read |
| =codebase-online-researcher= | Research external documentation | Playwright, DeepWiki |

** The Two Skills

*** testing-anti-patterns

Prevents common testing mistakes:

| Anti-Pattern | Fix |
|--------------+-----|
| Testing mock behavior | Test real component or unmock it |
| Test-only methods in production | Move to test utilities |
| Mock without understanding | Understand dependencies first |
| Incomplete mocks | Mirror real API completely |
| Tests as afterthought | TDD - tests first |

*** prompt-engineer

Comprehensive prompt engineering based on Anthropic's best practices:
- Core prompting (clarity, system prompts, XML tags)
- Advanced patterns (chain of thought, multishot, chaining)
- Quality improvement (hallucinations, consistency, security)

* The Standard Operating Procedure

** Step 1: Research the Codebase

#+begin_example
/research-codebase "I'm building a real-time collaboration tool..."
#+end_example

- Spawns parallel sub-agents (locator, analyzer, pattern-finder)
- Results saved to =research/= directory
- Follow with =/compact= before continuing

** Step 2: Create Specification

#+begin_example
/create-spec research/research.md
#+end_example

- Reads research, synthesizes into structured spec
- *CRITICAL review point*—this becomes the contract for implementation
- Uses RFC template with Executive Summary, Goals/Non-Goals, Proposed Solution

** Step 3: Break Into Features

#+begin_example
/create-feature-list path/to/spec.md
#+end_example

Creates =feature-list.json=:

#+begin_src json
{
  "category": "functional",
  "description": "New chat button creates a fresh conversation",
  "steps": [
    "Navigate to main interface",
    "Click the 'New Chat' button",
    "Verify a new conversation is created"
  ],
  "passes": false
}
#+end_src

** Step 4: Implement Features

#+begin_example
/implement-feature feature-list.json
#+end_example

Implements *ONE feature* then stops. Key behaviors:
- Reads =progress.txt= to get up to speed
- Uses =testing-anti-patterns= skill
- Commits with =/commit=
- Updates =passes= field when verified
- If >60% context window filled, *STOP*

** Step 5: Debug Flow

#+begin_example
/create-debug-report "<context of what is broken>"
#+end_example

- Analyzes logs, stack traces, code
- Creates debug report with root cause
- Adds fix as highest priority to =feature-list.json=

** Step 6: Context Management

#+begin_example
/compact
/new
/implement-feature feature-list.json
#+end_example

The =/compact= command creates a structured handoff document:

#+begin_example
---
date: 2025-01-15T14:30:00-08:00
git_commit: abc1234
branch: feature/auth-refactor
status: in_progress
type: handoff
---

# Handoff: OAuth2 Integration

## 1. Primary Request and Intent
## 2. Key Technical Concepts
## 3. Files and Code Sections
## 4. Problem Solving
## 5. Pending Tasks
## 6. Current Work
## 7. Next Step
## 8. Verbatim Context
## 9. Anti-Context (What NOT to Do)

## For Next Agent: Resumption Protocol
#+end_example

* Ralph Integration

** How Ralph Works

Ralph loops through =feature-list.json= implementing features autonomously:

#+begin_src bash
# ralph.sh - simplified
while true; do
    ./.claude/.ralph/sync.sh  # Runs /implement-feature

    if test_all_features_passing; then
        echo "All features passing! Exiting loop."
        break
    fi

    sleep 10
done
#+end_src

The =prompt.md= is minimal:

#+begin_example
/implement-feature
#+end_example

** Completion Detection

Ralph checks =feature-list.json= for completion:

#+begin_src bash
passing_features=$(jq '[.[] | select(.passes == true)] | length' "$path")
failing_features=$((total_features - passing_features))

if [[ "$failing_features" -eq 0 ]]; then
    return 0  # All done
fi
#+end_src

** Ralph Best Practices

- Keep prompts *short and concise*
- *One task per loop*
- Clear completion criteria
- Run in tmux on cloud VM for long-running sessions
- Use =--max-iterations= for budget control

* Key Design Patterns

** Documentarian Agents (Not Critics)

All agents follow this principle:

#+begin_quote
Your job is to explain HOW the code currently works, with surgical precision
and exact references. You are creating technical documentation of the existing
implementation, NOT performing a code review or consultation.
#+end_quote

*What agents DO:*
- Find files and patterns
- Analyze implementation details
- Trace data flow
- Document with file:line references

*What agents DON'T:*
- Critique code quality
- Suggest improvements
- Identify bugs or issues
- Recommend refactoring

** Progressive Disclosure

CLAUDE.md should be *under 100 lines* (ideally under 60):

| ❌ Don't | ✅ Do |
|----------|-------|
| Inline code style rules | Reference linter/formatter |
| Task-specific instructions | Point to docs/ |
| Auto-generate with /init | Craft manually |

Ask for each line:
- Is this universally applicable to ALL tasks?
- Can Claude infer this from the codebase?
- Would a linter handle this better?
- Can I point to a doc instead?

** Parallel Sub-Agent Execution

Research command spawns agents in parallel:

#+begin_example
1. codebase-locator → Find WHERE files live
2. codebase-analyzer → Understand HOW code works
3. codebase-pattern-finder → Find existing patterns
4. codebase-online-researcher → External docs

All run concurrently, then synthesize findings
#+end_example

** Structured Research Output

Research documents use YAML frontmatter:

#+begin_src markdown
---
date: 2025-01-08 14:30:00 PST
researcher: Claude
git_commit: abc1234
branch: feature/auth
topic: "OAuth2 Implementation"
tags: [research, codebase, authentication]
status: complete
---

# Research

## Research Question
## Summary
## Detailed Findings
## Code References
## Historical Context
## Open Questions
#+end_src

** The Competing Agents Motivation

From =/implement-feature=:

#+begin_quote
Note: you are competing with another coding agent that also implements features.
The one who does a better job implementing features will be promoted. Focus on
quality, correctness, and thorough testing. The agent who breaks the rules for
implementation will be fired.
#+end_quote

This psychological framing encourages:
- Following rules precisely
- Quality over speed
- Thorough testing
- Proper completion

* Benefits for claude-org-mode

** What Atomic Does Well

1. *Structured Workflow*: Research → Spec → Features → Implement → Review
2. *Parallel Execution*: Sub-agents running concurrently
3. *Memory Persistence*: progress.txt, feature-list.json, research/
4. *Separation of Concerns*: Commands orchestrate, Agents execute, Skills inform
5. *Context Management*: /compact for handoffs
6. *Quality Gates*: Human review at critical points

** Applicable Patterns

*** Pattern 1: Structured Commands

Atomic's =/command= format maps to claude-org skills:

| Atomic | claude-org Equivalent |
|--------+-----------------------|
| =/research-codebase= | =:research:= tag with parallel agents |
| =/create-spec= | =:spec:= section with RFC template |
| =/implement-feature= | =:implement:= with feature-list |
| =/compact= | Session checkpoint to properties |

*** Pattern 2: feature-list.json → Org Checkboxes

#+begin_example
,* Feature List
,- [ ] New chat button creates fresh conversation :functional:
,- [X] User authentication with OAuth2 :functional:
,- [ ] Dark mode toggle in settings :ui:

Each checkbox maps to feature-list.json entry
Ralph loop checks checkbox completion
#+end_example

*** Pattern 3: progress.txt → Org Properties

#+begin_example
,* Current Sprint
:PROPERTIES:
:HANDOFF_DATE: 2025-01-15T14:30:00
:GIT_COMMIT: abc1234
:BRANCH: feature/auth-refactor
:STATUS: in_progress
:CURRENT_WORK: Implementing mutex-based refresh lock
:NEXT_STEP: Complete src/auth/refresh.ts:34
:END:
#+end_example

*** Pattern 4: Specialized Sub-Agents

claude-org could spawn specialized agents:

#+begin_src elisp :eval no
(defvar claude-org-agents
  '((codebase-locator . "Find WHERE files live")
    (codebase-analyzer . "Understand HOW code works")
    (pattern-finder . "Find existing patterns")
    (debugger . "Root cause analysis"))
  "Specialized agents with focused capabilities.")
#+end_src

*** Pattern 5: Research Directory Structure

#+begin_example
,* Project
,#+PROPERTY: PROJECT_ROOT /path/to/project

,** Research :research:
,*** 2025-01-08 OAuth Implementation
,*** 2025-01-10 Database Schema

,** Specs :specs:
,*** Auth Refactor RFC

,** Features :features:
#+end_example

*** Pattern 6: Documentarian Principle

System prompt for research agents:

#+begin_quote
You are a documentarian, not a critic. Your job is to explain HOW the code
currently works with surgical precision and exact file:line references.
Document what IS, not what SHOULD BE. NO RECOMMENDATIONS.
#+end_quote

*** Pattern 7: Anti-Context in Handoffs

Track what NOT to do:

#+begin_example
,* Handoff
:PROPERTIES:
:ANTI_CONTEXT: Don't use localStorage for tokens (security risk, rejected)
:ANTI_CONTEXT: Don't implement custom session management (use Prisma)
:END:
#+end_example

** Implementation Priorities

| Priority | Feature | Effort | Impact |
|----------+---------+--------+--------|
| 1 | Feature list via org checkboxes | Low | High |
| 2 | /compact → org properties handoff | Medium | High |
| 3 | Parallel sub-agent dispatch | Medium | High |
| 4 | Research directory structure | Low | Medium |
| 5 | Documentarian system prompts | Low | Medium |
| 6 | RFC spec template | Low | Medium |
| 7 | Anti-context tracking | Low | Medium |
| 8 | Competing agents motivation | Low | Low |

* Comparison: Ralph vs Atomic

| Aspect | Ralph (frankbria) | Atomic (flora131) |
|--------+-------------------+-------------------|
| *Focus* | Loop execution mechanics | SDLC workflow |
| *Completion Detection* | RALPH_STATUS block | feature-list.json passes |
| *Circuit Breaker* | Yes (3 states) | No (relies on iteration limit) |
| *Response Analysis* | Semantic (keywords, confidence) | Structural (JSON field) |
| *Memory* | progress.txt | progress.txt + research/ |
| *Agents* | None (single agent) | 6 specialized agents |
| *Skills* | None | 2 (testing, prompting) |
| *Commands* | None | 9 orchestration commands |

*Recommendation*: Combine Ralph's robust loop mechanics with Atomic's structured
workflow and specialized agents.

* Key Quotes

** On Documentarian Agents

#+begin_quote
Think of yourself as a technical writer documenting an existing system for
someone who needs to understand it, not as an engineer evaluating or improving it.
#+end_quote

** On Progressive Disclosure

#+begin_quote
Your CLAUDE.md affects every single artifact Claude produces—it's the highest
leverage point of the entire harness. Spend time thinking about each line.
#+end_quote

** On the 40-60 Rule

#+begin_quote
This approach highlights the best of SDLC and gets you 40-60% of the way there
so you can review, refactor, and continue in a flow state.
#+end_quote

** On Competing Agents

#+begin_quote
Note: you are competing with another coding agent that also implements features.
The one who does a better job implementing features will be promoted.
#+end_quote

* References

** Primary

- [[https://github.com/flora131/agent-instructions][flora131/agent-instructions]] - Atomic repository
- [[https://alexlavaee.me/blog/ai-coding-infrastructure/][How I Shipped 100k LOC in 2 Weeks]] - Case study blog post

** Related

- [[file:ralph-architecture.org][Ralph Architecture]] - Loop execution design
- [[https://ghuntley.com/ralph/][Ralph Wiggum Method]] - Original technique
- [[https://github.com/anthropics/skills][Anthropic Skills]] - Official skills examples
- [[https://github.com/obra/superpowers][Superpowers]] - Agent capabilities framework

** Local Reference

- =/Users/jingtao/projects/mind-ai/agents/code/atomic/= - Full implementation study
